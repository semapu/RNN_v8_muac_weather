{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAutohr: Sergi Mas Pujol\\nLast update: 16/12/2020\\n\\nPython version: 3.6\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Autohr: Sergi Mas Pujol\n",
    "Last update: 16/12/2020\n",
    "\n",
    "Python version: 3.6\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(4)\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "random.seed(7)\n",
    "from random import sample\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "\n",
    "from utils_samplesTraining import read_REGULATIONS_file\n",
    "from utils_timeProcessing import from_YYYYMMDDHHMMSS_to_HHMMSS_withTwoDots, \\\n",
    "                                 substract_minutes_given_HHSSMM, add_minutes_given_HHSSMM, \\\n",
    "                                 from_YYYYMMDD_to_DDMMYYYY_given_separator, \\\n",
    "                                 listDays_betweenTwoDates, \\\n",
    "                                 from_YYYYMMDDHHMMSS_to_HHMMSS\n",
    "from utils_samplesTraining import readAssociatedFile_fromAIRAC_givenDate, \\\n",
    "                                  extract_regulations,\\\n",
    "                                  addIntervals_toFinalConjunt\n",
    "from generator import extract_days_timestamps_volumes_labels_days_with_regulations, \\\n",
    "                      extract_features_from_list_days_and_timestamps\n",
    "\n",
    "from generator_weather import extract_weather_information_from_list_days_and_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sergi/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sectorName = 'BOLN'\n",
    "# sectorName = 'D6WH'\n",
    "# sectorName = 'B3EH'\n",
    "\n",
    "sectorName = 'HRHR'\n",
    "# sectorName = 'HSOL'\n",
    "# sectorName = 'B3LL'\n",
    "\n",
    "# sectorName = 'LFEEHR'\n",
    "\n",
    "# MASD3WLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the start timestamp of the regulation -> Considered time before and after\n",
    "# Temporal gaps in minutes\n",
    "gap_before_start_time = 0\n",
    "gap_after_start_time = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 32\n",
    "\n",
    "# Used to extract more samples from a particular sector\n",
    "if sectorName == 'BOLN':\n",
    "    num_additional_samples_per_day = 25\n",
    "else:\n",
    "    num_additional_samples_per_day = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_weather_features = 7\n",
    "num_weather_features = 16\n",
    "num_metric_per_weather_feature = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare / Extreact data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Extract the available regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGULATIONS = read_REGULATIONS_file('./20190604_20191020_REGULATIONS.csv')\n",
    "\n",
    "REGULATIONS_from_given_sector = REGULATIONS.loc[(REGULATIONS[\"traffic_volume\"] == ' MAS'+sectorName+' ') &\n",
    "                                                (REGULATIONS[\"regulation_reason\"].isin([' W-Weather '])) & \n",
    "                                                (REGULATIONS[\"location_type\"] == ' En route ') &\n",
    "                                                (REGULATIONS[\"cancel_time\"] == '  ')\n",
    "                                               ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergi/.local/lib/python3.6/site-packages/pandas/core/indexing.py:376: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/home/sergi/.local/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# \".strip() -> Remove all the white spaaces in the timestamp\"\n",
    "\n",
    "REGULATIONS_from_given_sector.loc[:, 'date_DDMMYYYY'] = REGULATIONS_from_given_sector.apply(lambda x: from_YYYYMMDD_to_DDMMYYYY_given_separator(x.target_date.strip(), '/'), axis=1)\n",
    "\n",
    "REGULATIONS_from_given_sector.loc[:, 'start_time_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: from_YYYYMMDDHHMMSS_to_HHMMSS_withTwoDots(x.start_time.strip()), axis=1)\n",
    "REGULATIONS_from_given_sector.loc[:, 'end_time_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: from_YYYYMMDDHHMMSS_to_HHMMSS_withTwoDots(x.end_time.strip()), axis=1)\n",
    "REGULATIONS_from_given_sector.loc[:, 'start_time_study_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: substract_minutes_given_HHSSMM(x.start_time_HHMMSS, gap_before_start_time), axis=1)\n",
    "REGULATIONS_from_given_sector.loc[:, 'end_time_study_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: add_minutes_given_HHSSMM(x.start_time_HHMMSS, gap_after_start_time), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove from the DataFrame all the rows outside the valid interval of days\n",
    "# Outside the date of the available AIRACS\n",
    "min_date = date(2019, 6, 4)\n",
    "max_date = date(2019, 9, 11) \n",
    "\n",
    "\n",
    "for index, row in REGULATIONS_from_given_sector.iterrows():\n",
    "        \n",
    "    date_split = row[\"date_DDMMYYYY\"].split(\"/\") # 0 -> day; 1 -> month; 2 -> year\n",
    "    date_object = date(int(date_split[2]), int(date_split[1]), int(date_split[0]))\n",
    "    \n",
    "    # Check if the regulation's date belong to the valid interval -> IF outside, drop the Regulation\n",
    "    if date_object < min_date or date_object > max_date:\n",
    "        REGULATIONS_from_given_sector = REGULATIONS_from_given_sector.drop(index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number regulations AFTER pre-processing:  15\n"
     ]
    }
   ],
   "source": [
    "print('Number regulations AFTER pre-processing: ', str(len(REGULATIONS_from_given_sector.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the different list of days and timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Samples without regulations from days without regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the days with regulations\n",
    "list_days_with_regulations = REGULATIONS_from_given_sector[\"date_DDMMYYYY\"].values\n",
    "\n",
    "# Initialize a list with all the possible days and the final list for the days without regulations\n",
    "list_all_possible_days = listDays_betweenTwoDates(min_date, max_date, 'DDMMYYYY', '/')\n",
    "list_days_without_regulations = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If a day does not appear in the list with reguilations -> No regulations for that day\n",
    "for day in list_all_possible_days:\n",
    "    if day not in list_days_with_regulations:\n",
    "        list_days_without_regulations.append(day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the days without regulations, we will generate random timestamps\n",
    "\n",
    "list_days_without_regulations_extended = list()\n",
    "start_time_samples_no_regulations = list()\n",
    "end_time_samples_no_regulations = list()\n",
    "\n",
    "for day in list_days_without_regulations:\n",
    "    # Iterate multiple time each day without regulations\n",
    "    for _ in range(0,1):\n",
    "        # Randomly create the hour and the minutes\n",
    "        hour = str(\"{:02d}\".format(random.randint(3,21))) # From 2 to 22 to avoid extrems (wrap around timestamps)\n",
    "        minute = str(\"{:02d}\".format(random.randint(0,50)))\n",
    "\n",
    "        # Create the timestamp\n",
    "        random_timestamps = hour + \":\" + minute + \":\" + '00'\n",
    "\n",
    "        # Append the day of the timestamp\n",
    "        list_days_without_regulations_extended.append(day)\n",
    "        \n",
    "        # Substract a given about to create the starting timestamp\n",
    "        start_timestamp = substract_minutes_given_HHSSMM(random_timestamps, gap_before_start_time)\n",
    "        start_time_samples_no_regulations.append(start_timestamp)\n",
    "\n",
    "        # Add a given about to create the ending timestamp\n",
    "        end_timestamp = add_minutes_given_HHSSMM(random_timestamps, gap_after_start_time)\n",
    "        end_time_samples_no_regulations.append(end_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 88, 88)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_days_without_regulations_extended), len(start_time_samples_no_regulations), \\\n",
    "len(end_time_samples_no_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample with & without regulations from days with regulations completly random \n",
    "##### It is possible to have sample with both categories (e.g. start NO Regs from Regs and then Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "REGULATIONS_from_given_sector.loc[:, 'start_regulations_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: from_YYYYMMDDHHMMSS_to_HHMMSS(x.start_time.strip()), axis=1)\n",
    "REGULATIONS_from_given_sector.loc[:, 'end_regulations_HHMMSS'] = REGULATIONS_from_given_sector.apply(lambda x: from_YYYYMMDDHHMMSS_to_HHMMSS(x.end_time.strip()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dates_with_regulations = REGULATIONS_from_given_sector[\"date_DDMMYYYY\"].values\n",
    "\n",
    "start_regulations = REGULATIONS_from_given_sector[\"start_regulations_HHMMSS\"].values\n",
    "end_regulations = REGULATIONS_from_given_sector[\"end_regulations_HHMMSS\"].values\n",
    "\n",
    "list_volumes_regulations = REGULATIONS_from_given_sector[\"traffic_volume\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_days_from_regulations, \\\n",
    "start_time_samples_days_from_regulations, \\\n",
    "end_time_samples_days_from_regulations, \\\n",
    "volumes_days_from_regulations, \\\n",
    "labels_days_from_regulations = extract_days_timestamps_volumes_labels_days_with_regulations(\n",
    "                                          list_dates_with_regulations, \n",
    "                                          start_regulations,\n",
    "                                          end_regulations,\n",
    "                                          list_volumes_regulations, \n",
    "                                          gap_before_start_time, \n",
    "                                          gap_after_start_time, \n",
    "                                          num_additional_samples_per_day=num_additional_samples_per_day,\n",
    "                                          min_timestamps_with_regulations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 387, 387, 387)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_days_from_regulations), len(start_time_samples_days_from_regulations), \\\n",
    "len(end_time_samples_days_from_regulations), len(volumes_days_from_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract all the features for the given dates and timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_days_without_regulations_extended = np.array(list_days_without_regulations_extended)\n",
    "start_time_samples_no_regulations = np.array(start_time_samples_no_regulations)\n",
    "end_time_samples_no_regulations = np.array(end_time_samples_no_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 30, 11)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_without_regulations = np.zeros((len(list_days_without_regulations_extended), \n",
    "                                       int(gap_before_start_time+gap_after_start_time), \n",
    "                                       11))\n",
    "X_days_without_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRHR | counter: 1\n",
      "HRHR | counter: 2\n",
      "HRHR | counter: 3\n",
      "HRHR | counter: 4\n",
      "HRHR | counter: 5\n",
      "HRHR | counter: 6\n",
      "HRHR | counter: 7\n",
      "HRHR | counter: 8\n",
      "HRHR | counter: 9\n",
      "HRHR | counter: 10\n",
      "HRHR | counter: 11\n",
      "HRHR | counter: 12\n",
      "HRHR | counter: 13\n",
      "HRHR | counter: 14\n",
      "HRHR | counter: 15\n",
      "HRHR | counter: 16\n",
      "HRHR | counter: 17\n",
      "HRHR | counter: 18\n",
      "HRHR | counter: 19\n",
      "HRHR | counter: 20\n",
      "HRHR | counter: 21\n",
      "HRHR | counter: 22\n",
      "HRHR | counter: 23\n",
      "HRHR | counter: 24\n",
      "HRHR | counter: 25\n",
      "HRHR | counter: 26\n",
      "HRHR | counter: 27\n",
      "HRHR | counter: 28\n",
      "HRHR | counter: 29\n",
      "HRHR | counter: 30\n",
      "HRHR | counter: 31\n",
      "HRHR | counter: 32\n",
      "HRHR | counter: 33\n",
      "HRHR | counter: 34\n",
      "HRHR | counter: 35\n",
      "HRHR | counter: 36\n",
      "HRHR | counter: 37\n",
      "HRHR | counter: 38\n",
      "HRHR | counter: 39\n",
      "HRHR | counter: 40\n",
      "HRHR | counter: 41\n",
      "HRHR | counter: 42\n",
      "HRHR | counter: 43\n",
      "HRHR | counter: 44\n",
      "HRHR | counter: 45\n",
      "HRHR | counter: 46\n",
      "HRHR | counter: 47\n",
      "HRHR | counter: 48\n",
      "HRHR | counter: 49\n",
      "HRHR | counter: 50\n",
      "HRHR | counter: 51\n",
      "HRHR | counter: 52\n",
      "HRHR | counter: 53\n",
      "HRHR | counter: 54\n",
      "HRHR | counter: 55\n",
      "HRHR | counter: 56\n",
      "HRHR | counter: 57\n",
      "HRHR | counter: 58\n",
      "HRHR | counter: 59\n",
      "HRHR | counter: 60\n",
      "HRHR | counter: 61\n",
      "HRHR | counter: 62\n",
      "HRHR | counter: 63\n",
      "HRHR | counter: 64\n",
      "HRHR | counter: 65\n",
      "HRHR | counter: 66\n",
      "HRHR | counter: 67\n",
      "HRHR | counter: 68\n",
      "HRHR | counter: 69\n",
      "HRHR | counter: 70\n",
      "HRHR | counter: 71\n",
      "HRHR | counter: 72\n",
      "HRHR | counter: 73\n",
      "HRHR | counter: 74\n",
      "HRHR | counter: 75\n",
      "HRHR | counter: 76\n",
      "HRHR | counter: 77\n",
      "HRHR | counter: 78\n",
      "HRHR | counter: 79\n",
      "HRHR | counter: 80\n",
      "HRHR | counter: 81\n",
      "HRHR | counter: 82\n",
      "HRHR | counter: 83\n",
      "HRHR | counter: 84\n",
      "HRHR | counter: 85\n",
      "HRHR | counter: 86\n",
      "HRHR | counter: 87\n",
      "HRHR | counter: 88\n"
     ]
    }
   ],
   "source": [
    "X_days_without_regulations = extract_features_from_list_days_and_timestamps(list_days_without_regulations_extended, \n",
    "                                                                           start_time_samples_no_regulations, \n",
    "                                                                           end_time_samples_no_regulations,\n",
    "                                                                           sectorName,\n",
    "                                                                           gap_before_start_time, gap_after_start_time,\n",
    "                                                                           X_days_without_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Counting_variables/Weather/X_days_without_regulations', X_days_without_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_days_from_regulations = np.array(list_days_from_regulations)\n",
    "start_time_samples_days_from_regulations = np.array(start_time_samples_days_from_regulations)\n",
    "end_time_samples_days_from_regulations = np.array(end_time_samples_days_from_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 30, 11)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_from_regulations = np.zeros((len(list_days_from_regulations), \n",
    "                                    int(gap_before_start_time+gap_after_start_time), \n",
    "                                    11))\n",
    "X_days_from_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSOL | counter: 1\n",
      "HSOL | counter: 2\n",
      "HSOL | counter: 3\n",
      "HSOL | counter: 4\n",
      "HSOL | counter: 5\n",
      "HSOL | counter: 6\n",
      "HSOL | counter: 7\n",
      "HSOL | counter: 8\n",
      "HSOL | counter: 9\n",
      "HSOL | counter: 10\n",
      "HSOL | counter: 11\n",
      "HSOL | counter: 12\n",
      "HSOL | counter: 13\n",
      "HSOL | counter: 14\n",
      "HSOL | counter: 15\n",
      "HSOL | counter: 16\n",
      "HSOL | counter: 17\n",
      "HSOL | counter: 18\n",
      "HSOL | counter: 19\n",
      "HSOL | counter: 20\n",
      "HSOL | counter: 21\n",
      "HSOL | counter: 22\n",
      "HSOL | counter: 23\n",
      "HSOL | counter: 24\n",
      "HSOL | counter: 25\n",
      "HSOL | counter: 26\n",
      "HSOL | counter: 27\n",
      "HSOL | counter: 28\n",
      "HSOL | counter: 29\n",
      "HSOL | counter: 30\n",
      "HSOL | counter: 31\n",
      "HSOL | counter: 32\n",
      "HSOL | counter: 33\n",
      "HSOL | counter: 34\n",
      "HSOL | counter: 35\n",
      "HSOL | counter: 36\n",
      "HSOL | counter: 37\n",
      "HSOL | counter: 38\n",
      "HSOL | counter: 39\n",
      "HSOL | counter: 40\n",
      "HSOL | counter: 41\n",
      "HSOL | counter: 42\n",
      "HSOL | counter: 43\n",
      "HSOL | counter: 44\n",
      "HSOL | counter: 45\n",
      "HSOL | counter: 46\n",
      "HSOL | counter: 47\n",
      "HSOL | counter: 48\n",
      "HSOL | counter: 49\n",
      "HSOL | counter: 50\n",
      "HSOL | counter: 51\n",
      "HSOL | counter: 52\n",
      "HSOL | counter: 53\n",
      "HSOL | counter: 54\n",
      "HSOL | counter: 55\n",
      "HSOL | counter: 56\n",
      "HSOL | counter: 57\n",
      "HSOL | counter: 58\n",
      "HSOL | counter: 59\n",
      "HSOL | counter: 60\n",
      "HSOL | counter: 61\n",
      "HSOL | counter: 62\n",
      "HSOL | counter: 63\n",
      "HSOL | counter: 64\n",
      "HSOL | counter: 65\n",
      "HSOL | counter: 66\n",
      "HSOL | counter: 67\n",
      "HSOL | counter: 68\n",
      "HSOL | counter: 69\n",
      "HSOL | counter: 70\n",
      "HSOL | counter: 71\n",
      "HSOL | counter: 72\n",
      "HSOL | counter: 73\n",
      "HSOL | counter: 74\n",
      "HSOL | counter: 75\n",
      "HSOL | counter: 76\n",
      "HSOL | counter: 77\n",
      "HSOL | counter: 78\n",
      "HSOL | counter: 79\n",
      "HSOL | counter: 80\n",
      "HSOL | counter: 81\n",
      "HSOL | counter: 82\n",
      "HSOL | counter: 83\n",
      "HSOL | counter: 84\n",
      "HSOL | counter: 85\n",
      "HSOL | counter: 86\n",
      "HSOL | counter: 87\n",
      "HSOL | counter: 88\n",
      "HSOL | counter: 89\n",
      "HSOL | counter: 90\n",
      "HSOL | counter: 91\n",
      "HSOL | counter: 92\n",
      "HSOL | counter: 93\n",
      "HSOL | counter: 94\n",
      "HSOL | counter: 95\n",
      "HSOL | counter: 96\n",
      "HSOL | counter: 97\n",
      "HSOL | counter: 98\n",
      "HSOL | counter: 99\n",
      "HSOL | counter: 100\n",
      "HSOL | counter: 101\n",
      "HSOL | counter: 102\n",
      "HSOL | counter: 103\n",
      "HSOL | counter: 104\n",
      "HSOL | counter: 105\n",
      "HSOL | counter: 106\n",
      "HSOL | counter: 107\n",
      "HSOL | counter: 108\n",
      "HSOL | counter: 109\n",
      "HSOL | counter: 110\n",
      "HSOL | counter: 111\n",
      "HSOL | counter: 112\n",
      "HSOL | counter: 113\n",
      "HSOL | counter: 114\n",
      "HSOL | counter: 115\n",
      "HSOL | counter: 116\n",
      "HSOL | counter: 117\n",
      "HSOL | counter: 118\n",
      "HSOL | counter: 119\n",
      "HSOL | counter: 120\n",
      "HSOL | counter: 121\n",
      "HSOL | counter: 122\n",
      "HSOL | counter: 123\n",
      "HSOL | counter: 124\n",
      "HSOL | counter: 125\n",
      "HSOL | counter: 126\n",
      "HSOL | counter: 127\n",
      "HSOL | counter: 128\n",
      "HSOL | counter: 129\n",
      "HSOL | counter: 130\n",
      "HSOL | counter: 131\n",
      "HSOL | counter: 132\n",
      "HSOL | counter: 133\n",
      "HSOL | counter: 134\n",
      "HSOL | counter: 135\n",
      "HSOL | counter: 136\n",
      "HSOL | counter: 137\n",
      "HSOL | counter: 138\n",
      "HSOL | counter: 139\n",
      "HSOL | counter: 140\n",
      "HSOL | counter: 141\n",
      "HSOL | counter: 142\n",
      "HSOL | counter: 143\n",
      "HSOL | counter: 144\n",
      "HSOL | counter: 145\n",
      "HSOL | counter: 146\n",
      "HSOL | counter: 147\n",
      "HSOL | counter: 148\n",
      "HSOL | counter: 149\n",
      "HSOL | counter: 150\n",
      "HSOL | counter: 151\n",
      "HSOL | counter: 152\n",
      "HSOL | counter: 153\n",
      "HSOL | counter: 154\n",
      "HSOL | counter: 155\n",
      "HSOL | counter: 156\n",
      "HSOL | counter: 157\n",
      "HSOL | counter: 158\n",
      "HSOL | counter: 159\n",
      "HSOL | counter: 160\n",
      "HSOL | counter: 161\n",
      "HSOL | counter: 162\n",
      "HSOL | counter: 163\n",
      "HSOL | counter: 164\n",
      "HSOL | counter: 165\n",
      "HSOL | counter: 166\n",
      "HSOL | counter: 167\n",
      "HSOL | counter: 168\n",
      "HSOL | counter: 169\n",
      "HSOL | counter: 170\n",
      "HSOL | counter: 171\n",
      "HSOL | counter: 172\n",
      "HSOL | counter: 173\n",
      "HSOL | counter: 174\n",
      "HSOL | counter: 175\n",
      "HSOL | counter: 176\n",
      "HSOL | counter: 177\n",
      "HSOL | counter: 178\n",
      "HSOL | counter: 179\n",
      "HSOL | counter: 180\n",
      "HSOL | counter: 181\n",
      "HSOL | counter: 182\n",
      "HSOL | counter: 183\n",
      "HSOL | counter: 184\n",
      "HSOL | counter: 185\n",
      "HSOL | counter: 186\n",
      "HSOL | counter: 187\n",
      "HSOL | counter: 188\n",
      "HSOL | counter: 189\n",
      "HSOL | counter: 190\n",
      "HSOL | counter: 191\n",
      "HSOL | counter: 192\n",
      "HSOL | counter: 193\n",
      "HSOL | counter: 194\n",
      "HSOL | counter: 195\n",
      "HSOL | counter: 196\n",
      "HSOL | counter: 197\n",
      "HSOL | counter: 198\n",
      "HSOL | counter: 199\n",
      "HSOL | counter: 200\n",
      "HSOL | counter: 201\n",
      "HSOL | counter: 202\n",
      "HSOL | counter: 203\n",
      "HSOL | counter: 204\n",
      "HSOL | counter: 205\n",
      "HSOL | counter: 206\n",
      "HSOL | counter: 207\n",
      "HSOL | counter: 208\n",
      "HSOL | counter: 209\n",
      "HSOL | counter: 210\n",
      "HSOL | counter: 211\n",
      "HSOL | counter: 212\n",
      "HSOL | counter: 213\n",
      "HSOL | counter: 214\n",
      "HSOL | counter: 215\n",
      "HSOL | counter: 216\n",
      "HSOL | counter: 217\n",
      "HSOL | counter: 218\n",
      "HSOL | counter: 219\n",
      "HSOL | counter: 220\n",
      "HSOL | counter: 221\n",
      "HSOL | counter: 222\n",
      "HSOL | counter: 223\n",
      "HSOL | counter: 224\n",
      "HSOL | counter: 225\n",
      "HSOL | counter: 226\n",
      "HSOL | counter: 227\n",
      "HSOL | counter: 228\n",
      "HSOL | counter: 229\n",
      "HSOL | counter: 230\n",
      "HSOL | counter: 231\n",
      "HSOL | counter: 232\n",
      "HSOL | counter: 233\n",
      "HSOL | counter: 234\n",
      "HSOL | counter: 235\n",
      "HSOL | counter: 236\n",
      "HSOL | counter: 237\n",
      "HSOL | counter: 238\n",
      "HSOL | counter: 239\n",
      "HSOL | counter: 240\n",
      "HSOL | counter: 241\n",
      "HSOL | counter: 242\n",
      "HSOL | counter: 243\n",
      "HSOL | counter: 244\n",
      "HSOL | counter: 245\n",
      "HSOL | counter: 246\n"
     ]
    }
   ],
   "source": [
    "X_days_from_regulations = extract_features_from_list_days_and_timestamps(list_days_from_regulations, \n",
    "                                                                       start_time_samples_days_from_regulations, \n",
    "                                                                       end_time_samples_days_from_regulations,\n",
    "                                                                       sectorName,\n",
    "                                                                       gap_before_start_time, gap_after_start_time,\n",
    "                                                                       X_days_from_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Counting_variables/Weather/X_days_from_regulations', X_days_from_regulations)\n",
    "np.save('./Counting_variables/Weather/labels_days_from_regulations', labels_days_from_regulations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the weather features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 30, 48)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_without_regulations_weather = np.zeros((len(list_days_without_regulations_extended), \n",
    "                                               int(gap_before_start_time+gap_after_start_time), \n",
    "                                               num_weather_features*num_metric_per_weather_feature))\n",
    "X_days_without_regulations_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 04/06/2019 | start:130900 | TV: HSOL\n",
      "day: 05/06/2019 | start:154100 | TV: HSOL\n",
      "day: 06/06/2019 | start:040400 | TV: HSOL\n",
      "day: 07/06/2019 | start:200600 | TV: HSOL\n",
      "day: 08/06/2019 | start:143700 | TV: HSOL\n",
      "day: 09/06/2019 | start:043200 | TV: HSOL\n",
      "day: 14/06/2019 | start:090200 | TV: HSOL\n",
      "day: 15/06/2019 | start:052700 | TV: HSOL\n",
      "day: 16/06/2019 | start:160400 | TV: HSOL\n",
      "day: 17/06/2019 | start:100500 | TV: HSOL\n",
      "day: 18/06/2019 | start:202700 | TV: HSOL\n",
      "day: 21/06/2019 | start:043600 | TV: HSOL\n",
      "day: 22/06/2019 | start:061400 | TV: HSOL\n",
      "day: 23/06/2019 | start:210300 | TV: HSOL\n",
      "day: 24/06/2019 | start:213700 | TV: HSOL\n",
      "day: 25/06/2019 | start:150300 | TV: HSOL\n",
      "day: 26/06/2019 | start:100200 | TV: HSOL\n",
      "day: 27/06/2019 | start:200800 | TV: HSOL\n",
      "day: 28/06/2019 | start:122600 | TV: HSOL\n",
      "day: 29/06/2019 | start:073400 | TV: HSOL\n",
      "day: 30/06/2019 | start:063600 | TV: HSOL\n",
      "day: 01/07/2019 | start:123500 | TV: HSOL\n",
      "day: 02/07/2019 | start:080600 | TV: HSOL\n",
      "day: 03/07/2019 | start:213600 | TV: HSOL\n",
      "day: 04/07/2019 | start:092300 | TV: HSOL\n",
      "day: 05/07/2019 | start:063500 | TV: HSOL\n",
      "day: 06/07/2019 | start:053600 | TV: HSOL\n",
      "day: 07/07/2019 | start:043900 | TV: HSOL\n",
      "day: 08/07/2019 | start:093100 | TV: HSOL\n",
      "day: 09/07/2019 | start:202700 | TV: HSOL\n",
      "day: 10/07/2019 | start:132900 | TV: HSOL\n",
      "day: 11/07/2019 | start:212900 | TV: HSOL\n",
      "day: 13/07/2019 | start:141900 | TV: HSOL\n",
      "day: 14/07/2019 | start:105000 | TV: HSOL\n",
      "day: 15/07/2019 | start:084400 | TV: HSOL\n",
      "day: 16/07/2019 | start:100500 | TV: HSOL\n",
      "day: 17/07/2019 | start:211900 | TV: HSOL\n",
      "day: 18/07/2019 | start:193100 | TV: HSOL\n",
      "day: 19/07/2019 | start:134600 | TV: HSOL\n",
      "day: 21/07/2019 | start:171800 | TV: HSOL\n",
      "day: 22/07/2019 | start:050700 | TV: HSOL\n",
      "day: 23/07/2019 | start:192600 | TV: HSOL\n",
      "day: 24/07/2019 | start:084800 | TV: HSOL\n",
      "day: 25/07/2019 | start:130900 | TV: HSOL\n",
      "day: 26/07/2019 | start:182600 | TV: HSOL\n",
      "day: 27/07/2019 | start:044200 | TV: HSOL\n",
      "day: 28/07/2019 | start:054800 | TV: HSOL\n",
      "day: 29/07/2019 | start:203600 | TV: HSOL\n",
      "day: 30/07/2019 | start:132100 | TV: HSOL\n",
      "day: 31/07/2019 | start:143800 | TV: HSOL\n",
      "day: 01/08/2019 | start:183700 | TV: HSOL\n",
      "day: 02/08/2019 | start:170400 | TV: HSOL\n",
      "day: 03/08/2019 | start:051700 | TV: HSOL\n",
      "day: 04/08/2019 | start:184400 | TV: HSOL\n",
      "day: 05/08/2019 | start:050300 | TV: HSOL\n",
      "day: 06/08/2019 | start:124100 | TV: HSOL\n",
      "day: 07/08/2019 | start:214300 | TV: HSOL\n",
      "day: 08/08/2019 | start:171800 | TV: HSOL\n",
      "day: 10/08/2019 | start:154200 | TV: HSOL\n",
      "day: 11/08/2019 | start:140100 | TV: HSOL\n",
      "day: 12/08/2019 | start:172200 | TV: HSOL\n",
      "day: 13/08/2019 | start:083900 | TV: HSOL\n",
      "day: 14/08/2019 | start:063100 | TV: HSOL\n",
      "day: 15/08/2019 | start:041300 | TV: HSOL\n",
      "day: 16/08/2019 | start:120800 | TV: HSOL\n",
      "day: 17/08/2019 | start:102500 | TV: HSOL\n",
      "day: 19/08/2019 | start:153100 | TV: HSOL\n",
      "day: 20/08/2019 | start:051000 | TV: HSOL\n",
      "day: 21/08/2019 | start:172500 | TV: HSOL\n",
      "day: 22/08/2019 | start:201700 | TV: HSOL\n",
      "day: 23/08/2019 | start:072700 | TV: HSOL\n",
      "day: 24/08/2019 | start:201700 | TV: HSOL\n",
      "day: 25/08/2019 | start:162200 | TV: HSOL\n",
      "day: 27/08/2019 | start:151400 | TV: HSOL\n",
      "day: 28/08/2019 | start:070500 | TV: HSOL\n",
      "day: 29/08/2019 | start:080900 | TV: HSOL\n",
      "day: 30/08/2019 | start:104200 | TV: HSOL\n",
      "day: 31/08/2019 | start:100000 | TV: HSOL\n",
      "day: 01/09/2019 | start:183700 | TV: HSOL\n",
      "day: 02/09/2019 | start:081600 | TV: HSOL\n",
      "day: 03/09/2019 | start:120000 | TV: HSOL\n",
      "day: 04/09/2019 | start:072600 | TV: HSOL\n",
      "day: 05/09/2019 | start:202300 | TV: HSOL\n",
      "day: 06/09/2019 | start:212000 | TV: HSOL\n",
      "day: 07/09/2019 | start:074400 | TV: HSOL\n",
      "day: 08/09/2019 | start:193900 | TV: HSOL\n",
      "day: 09/09/2019 | start:042900 | TV: HSOL\n",
      "day: 10/09/2019 | start:202500 | TV: HSOL\n",
      "day: 11/09/2019 | start:152500 | TV: HSOL\n"
     ]
    }
   ],
   "source": [
    "X_days_without_regulations_weather = extract_weather_information_from_list_days_and_timestamps(\n",
    "    list_days_without_regulations_extended, \n",
    "    start_time_samples_no_regulations, \n",
    "    end_time_samples_no_regulations,\n",
    "    sectorName,\n",
    "    num_weather_features,\n",
    "    num_metric_per_weather_feature,\n",
    "    X_days_without_regulations_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Counting_variables/Weather/X_days_without_regulations_weather', X_days_without_regulations_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246, 30, 48)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_from_regulations_weather = np.zeros((len(list_days_from_regulations), \n",
    "                                            int(gap_before_start_time+gap_after_start_time), \n",
    "                                            num_weather_features*num_metric_per_weather_feature))\n",
    "X_days_from_regu<lations_weather.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 10/06/2019 | start:174000 | TV: HSOL\n",
      "day: 10/06/2019 | start:182900 | TV: HSOL\n",
      "day: 10/06/2019 | start:193300 | TV: HSOL\n",
      "day: 10/06/2019 | start:074400 | TV: HSOL\n",
      "day: 10/06/2019 | start:192900 | TV: HSOL\n",
      "day: 10/06/2019 | start:141100 | TV: HSOL\n",
      "day: 10/06/2019 | start:034000 | TV: HSOL\n",
      "day: 10/06/2019 | start:094000 | TV: HSOL\n",
      "day: 10/06/2019 | start:165000 | TV: HSOL\n",
      "day: 10/06/2019 | start:171900 | TV: HSOL\n",
      "day: 10/06/2019 | start:183200 | TV: HSOL\n",
      "day: 10/06/2019 | start:073700 | TV: HSOL\n",
      "day: 10/06/2019 | start:193600 | TV: HSOL\n",
      "day: 10/06/2019 | start:191800 | TV: HSOL\n",
      "day: 10/06/2019 | start:184900 | TV: HSOL\n",
      "day: 10/06/2019 | start:194300 | TV: HSOL\n",
      "day: 10/06/2019 | start:194800 | TV: HSOL\n",
      "day: 10/06/2019 | start:192200 | TV: HSOL\n",
      "day: 10/06/2019 | start:184200 | TV: HSOL\n",
      "day: 10/06/2019 | start:104300 | TV: HSOL\n",
      "day: 10/06/2019 | start:114500 | TV: HSOL\n",
      "day: 11/06/2019 | start:063500 | TV: HSOL\n",
      "day: 11/06/2019 | start:124200 | TV: HSOL\n",
      "day: 11/06/2019 | start:062400 | TV: HSOL\n",
      "day: 11/06/2019 | start:194600 | TV: HSOL\n",
      "day: 11/06/2019 | start:183000 | TV: HSOL\n",
      "day: 11/06/2019 | start:083700 | TV: HSOL\n",
      "day: 11/06/2019 | start:203600 | TV: HSOL\n",
      "day: 11/06/2019 | start:192500 | TV: HSOL\n",
      "day: 11/06/2019 | start:082200 | TV: HSOL\n",
      "day: 11/06/2019 | start:073500 | TV: HSOL\n",
      "day: 11/06/2019 | start:053400 | TV: HSOL\n",
      "day: 11/06/2019 | start:113300 | TV: HSOL\n",
      "day: 11/06/2019 | start:192200 | TV: HSOL\n",
      "day: 11/06/2019 | start:191900 | TV: HSOL\n",
      "day: 11/06/2019 | start:195000 | TV: HSOL\n",
      "day: 11/06/2019 | start:194200 | TV: HSOL\n",
      "day: 11/06/2019 | start:201300 | TV: HSOL\n",
      "day: 11/06/2019 | start:194400 | TV: HSOL\n",
      "day: 12/06/2019 | start:054000 | TV: HSOL\n",
      "day: 12/06/2019 | start:182800 | TV: HSOL\n",
      "day: 12/06/2019 | start:171700 | TV: HSOL\n",
      "day: 12/06/2019 | start:171400 | TV: HSOL\n",
      "day: 12/06/2019 | start:193800 | TV: HSOL\n",
      "day: 12/06/2019 | start:192700 | TV: HSOL\n",
      "day: 12/06/2019 | start:183500 | TV: HSOL\n",
      "day: 12/06/2019 | start:183800 | TV: HSOL\n",
      "day: 12/06/2019 | start:152900 | TV: HSOL\n",
      "day: 12/06/2019 | start:091000 | TV: HSOL\n",
      "day: 12/06/2019 | start:153400 | TV: HSOL\n",
      "day: 12/06/2019 | start:162700 | TV: HSOL\n",
      "day: 12/06/2019 | start:125000 | TV: HSOL\n",
      "day: 12/06/2019 | start:161100 | TV: HSOL\n",
      "day: 12/06/2019 | start:154500 | TV: HSOL\n",
      "day: 12/06/2019 | start:163100 | TV: HSOL\n",
      "day: 12/06/2019 | start:173100 | TV: HSOL\n",
      "day: 12/06/2019 | start:173700 | TV: HSOL\n",
      "day: 12/06/2019 | start:173700 | TV: HSOL\n",
      "day: 12/06/2019 | start:164000 | TV: HSOL\n",
      "day: 12/06/2019 | start:154300 | TV: HSOL\n",
      "day: 12/06/2019 | start:173800 | TV: HSOL\n",
      "day: 12/06/2019 | start:074300 | TV: HSOL\n",
      "day: 12/06/2019 | start:104600 | TV: HSOL\n",
      "day: 13/06/2019 | start:195000 | TV: HSOL\n",
      "day: 13/06/2019 | start:161700 | TV: HSOL\n",
      "day: 13/06/2019 | start:202900 | TV: HSOL\n",
      "day: 13/06/2019 | start:162900 | TV: HSOL\n",
      "day: 13/06/2019 | start:161500 | TV: HSOL\n",
      "day: 13/06/2019 | start:182200 | TV: HSOL\n",
      "day: 13/06/2019 | start:121600 | TV: HSOL\n",
      "day: 13/06/2019 | start:184900 | TV: HSOL\n",
      "day: 13/06/2019 | start:131700 | TV: HSOL\n",
      "day: 13/06/2019 | start:193900 | TV: HSOL\n",
      "day: 13/06/2019 | start:153300 | TV: HSOL\n",
      "day: 13/06/2019 | start:172000 | TV: HSOL\n",
      "day: 13/06/2019 | start:064500 | TV: HSOL\n",
      "day: 13/06/2019 | start:182200 | TV: HSOL\n",
      "day: 13/06/2019 | start:144400 | TV: HSOL\n",
      "day: 13/06/2019 | start:181100 | TV: HSOL\n",
      "day: 13/06/2019 | start:162500 | TV: HSOL\n",
      "day: 13/06/2019 | start:171400 | TV: HSOL\n",
      "day: 13/06/2019 | start:113100 | TV: HSOL\n",
      "day: 13/06/2019 | start:173400 | TV: HSOL\n",
      "day: 13/06/2019 | start:132000 | TV: HSOL\n",
      "day: 13/06/2019 | start:183800 | TV: HSOL\n",
      "day: 13/06/2019 | start:174900 | TV: HSOL\n",
      "day: 13/06/2019 | start:063900 | TV: HSOL\n",
      "day: 19/06/2019 | start:103800 | TV: HSOL\n",
      "day: 19/06/2019 | start:212200 | TV: HSOL\n",
      "day: 19/06/2019 | start:144200 | TV: HSOL\n",
      "day: 19/06/2019 | start:142300 | TV: HSOL\n",
      "day: 19/06/2019 | start:042300 | TV: HSOL\n",
      "day: 19/06/2019 | start:163300 | TV: HSOL\n",
      "day: 19/06/2019 | start:162800 | TV: HSOL\n",
      "day: 19/06/2019 | start:123600 | TV: HSOL\n",
      "day: 19/06/2019 | start:124600 | TV: HSOL\n",
      "day: 19/06/2019 | start:163600 | TV: HSOL\n",
      "day: 19/06/2019 | start:153500 | TV: HSOL\n",
      "day: 19/06/2019 | start:143900 | TV: HSOL\n",
      "day: 19/06/2019 | start:151500 | TV: HSOL\n",
      "day: 19/06/2019 | start:214900 | TV: HSOL\n",
      "day: 19/06/2019 | start:192000 | TV: HSOL\n",
      "day: 19/06/2019 | start:192000 | TV: HSOL\n",
      "day: 19/06/2019 | start:151500 | TV: HSOL\n",
      "day: 19/06/2019 | start:192000 | TV: HSOL\n",
      "day: 19/06/2019 | start:153200 | TV: HSOL\n",
      "day: 19/06/2019 | start:091200 | TV: HSOL\n",
      "day: 19/06/2019 | start:174500 | TV: HSOL\n",
      "day: 19/06/2019 | start:143800 | TV: HSOL\n",
      "day: 19/06/2019 | start:193800 | TV: HSOL\n",
      "day: 19/06/2019 | start:183900 | TV: HSOL\n",
      "day: 19/06/2019 | start:172100 | TV: HSOL\n",
      "day: 19/06/2019 | start:183500 | TV: HSOL\n",
      "day: 19/06/2019 | start:163300 | TV: HSOL\n",
      "day: 19/06/2019 | start:191500 | TV: HSOL\n",
      "day: 19/06/2019 | start:044200 | TV: HSOL\n",
      "day: 19/06/2019 | start:071100 | TV: HSOL\n",
      "day: 19/06/2019 | start:182800 | TV: HSOL\n",
      "day: 19/06/2019 | start:144900 | TV: HSOL\n",
      "day: 19/06/2019 | start:194000 | TV: HSOL\n",
      "day: 20/06/2019 | start:085000 | TV: HSOL\n",
      "day: 20/06/2019 | start:045000 | TV: HSOL\n",
      "day: 20/06/2019 | start:174500 | TV: HSOL\n",
      "day: 20/06/2019 | start:062600 | TV: HSOL\n",
      "day: 20/06/2019 | start:193300 | TV: HSOL\n",
      "day: 20/06/2019 | start:164700 | TV: HSOL\n",
      "day: 20/06/2019 | start:081300 | TV: HSOL\n",
      "day: 20/06/2019 | start:164900 | TV: HSOL\n",
      "day: 20/06/2019 | start:184400 | TV: HSOL\n",
      "day: 20/06/2019 | start:171500 | TV: HSOL\n",
      "day: 20/06/2019 | start:172100 | TV: HSOL\n",
      "day: 20/06/2019 | start:091500 | TV: HSOL\n",
      "day: 20/06/2019 | start:102200 | TV: HSOL\n",
      "day: 20/06/2019 | start:132200 | TV: HSOL\n",
      "day: 20/06/2019 | start:191000 | TV: HSOL\n",
      "day: 20/06/2019 | start:083200 | TV: HSOL\n",
      "day: 20/06/2019 | start:094400 | TV: HSOL\n",
      "day: 12/07/2019 | start:133700 | TV: HSOL\n",
      "day: 12/07/2019 | start:121300 | TV: HSOL\n",
      "day: 12/07/2019 | start:143000 | TV: HSOL\n",
      "day: 12/07/2019 | start:194000 | TV: HSOL\n",
      "day: 12/07/2019 | start:124900 | TV: HSOL\n",
      "day: 12/07/2019 | start:191600 | TV: HSOL\n",
      "day: 12/07/2019 | start:144000 | TV: HSOL\n",
      "day: 12/07/2019 | start:192600 | TV: HSOL\n",
      "day: 12/07/2019 | start:184500 | TV: HSOL\n",
      "day: 12/07/2019 | start:063500 | TV: HSOL\n",
      "day: 12/07/2019 | start:053700 | TV: HSOL\n",
      "day: 12/07/2019 | start:191900 | TV: HSOL\n",
      "day: 12/07/2019 | start:174500 | TV: HSOL\n",
      "day: 12/07/2019 | start:132000 | TV: HSOL\n",
      "day: 12/07/2019 | start:173800 | TV: HSOL\n",
      "day: 12/07/2019 | start:114700 | TV: HSOL\n",
      "day: 12/07/2019 | start:124900 | TV: HSOL\n",
      "day: 12/07/2019 | start:071900 | TV: HSOL\n",
      "day: 12/07/2019 | start:134800 | TV: HSOL\n",
      "day: 12/07/2019 | start:193200 | TV: HSOL\n",
      "day: 12/07/2019 | start:092600 | TV: HSOL\n",
      "day: 12/07/2019 | start:062000 | TV: HSOL\n",
      "day: 12/07/2019 | start:162700 | TV: HSOL\n",
      "day: 12/07/2019 | start:153900 | TV: HSOL\n",
      "day: 12/07/2019 | start:162400 | TV: HSOL\n",
      "day: 12/07/2019 | start:195000 | TV: HSOL\n",
      "day: 12/07/2019 | start:123900 | TV: HSOL\n",
      "day: 12/07/2019 | start:151000 | TV: HSOL\n",
      "day: 12/07/2019 | start:115000 | TV: HSOL\n",
      "day: 12/07/2019 | start:155000 | TV: HSOL\n",
      "day: 12/07/2019 | start:183900 | TV: HSOL\n",
      "day: 12/07/2019 | start:034900 | TV: HSOL\n",
      "day: 12/07/2019 | start:192100 | TV: HSOL\n",
      "day: 12/07/2019 | start:131000 | TV: HSOL\n",
      "day: 12/07/2019 | start:154100 | TV: HSOL\n",
      "day: 12/07/2019 | start:184200 | TV: HSOL\n",
      "day: 12/07/2019 | start:144300 | TV: HSOL\n",
      "day: 20/07/2019 | start:151300 | TV: HSOL\n",
      "day: 20/07/2019 | start:165000 | TV: HSOL\n",
      "day: 20/07/2019 | start:144700 | TV: HSOL\n",
      "day: 20/07/2019 | start:154300 | TV: HSOL\n",
      "day: 20/07/2019 | start:081800 | TV: HSOL\n",
      "day: 20/07/2019 | start:163900 | TV: HSOL\n",
      "day: 20/07/2019 | start:164900 | TV: HSOL\n",
      "day: 20/07/2019 | start:084900 | TV: HSOL\n",
      "day: 20/07/2019 | start:171700 | TV: HSOL\n",
      "day: 20/07/2019 | start:161400 | TV: HSOL\n",
      "day: 20/07/2019 | start:165000 | TV: HSOL\n",
      "day: 20/07/2019 | start:162600 | TV: HSOL\n",
      "day: 20/07/2019 | start:153100 | TV: HSOL\n",
      "day: 20/07/2019 | start:192700 | TV: HSOL\n",
      "day: 20/07/2019 | start:044200 | TV: HSOL\n",
      "day: 20/07/2019 | start:154900 | TV: HSOL\n",
      "day: 09/08/2019 | start:175000 | TV: HSOL\n",
      "day: 09/08/2019 | start:033300 | TV: HSOL\n",
      "day: 09/08/2019 | start:214700 | TV: HSOL\n",
      "day: 09/08/2019 | start:164600 | TV: HSOL\n",
      "day: 09/08/2019 | start:201600 | TV: HSOL\n",
      "day: 09/08/2019 | start:204100 | TV: HSOL\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "day: 09/08/2019 | start:172600 | TV: HSOL\n",
      "day: 09/08/2019 | start:133300 | TV: HSOL\n",
      "day: 09/08/2019 | start:174000 | TV: HSOL\n",
      "day: 09/08/2019 | start:081900 | TV: HSOL\n",
      "day: 09/08/2019 | start:063300 | TV: HSOL\n",
      "day: 09/08/2019 | start:183400 | TV: HSOL\n",
      "day: 09/08/2019 | start:172700 | TV: HSOL\n",
      "day: 09/08/2019 | start:044900 | TV: HSOL\n",
      "day: 09/08/2019 | start:211900 | TV: HSOL\n",
      "day: 09/08/2019 | start:183200 | TV: HSOL\n",
      "day: 09/08/2019 | start:201500 | TV: HSOL\n",
      "day: 09/08/2019 | start:204500 | TV: HSOL\n",
      "day: 09/08/2019 | start:183400 | TV: HSOL\n",
      "day: 09/08/2019 | start:192600 | TV: HSOL\n",
      "day: 09/08/2019 | start:193000 | TV: HSOL\n",
      "day: 09/08/2019 | start:184200 | TV: HSOL\n",
      "day: 09/08/2019 | start:191900 | TV: HSOL\n",
      "day: 09/08/2019 | start:101200 | TV: HSOL\n",
      "day: 09/08/2019 | start:183300 | TV: HSOL\n",
      "day: 09/08/2019 | start:092600 | TV: HSOL\n",
      "day: 18/08/2019 | start:174700 | TV: HSOL\n",
      "day: 18/08/2019 | start:132200 | TV: HSOL\n",
      "day: 18/08/2019 | start:174100 | TV: HSOL\n",
      "day: 18/08/2019 | start:083300 | TV: HSOL\n",
      "day: 18/08/2019 | start:181300 | TV: HSOL\n",
      "day: 18/08/2019 | start:183400 | TV: HSOL\n",
      "day: 18/08/2019 | start:101400 | TV: HSOL\n",
      "day: 18/08/2019 | start:053800 | TV: HSOL\n",
      "day: 18/08/2019 | start:133900 | TV: HSOL\n",
      "day: 18/08/2019 | start:061900 | TV: HSOL\n",
      "day: 18/08/2019 | start:045000 | TV: HSOL\n",
      "day: 18/08/2019 | start:112500 | TV: HSOL\n",
      "day: 18/08/2019 | start:121900 | TV: HSOL\n",
      "day: 18/08/2019 | start:162300 | TV: HSOL\n",
      "day: 18/08/2019 | start:181500 | TV: HSOL\n",
      "day: 18/08/2019 | start:033600 | TV: HSOL\n",
      "day: 18/08/2019 | start:181800 | TV: HSOL\n",
      "day: 18/08/2019 | start:174300 | TV: HSOL\n",
      "day: 18/08/2019 | start:042800 | TV: HSOL\n",
      "day: 26/08/2019 | start:063500 | TV: HSOL\n",
      "day: 26/08/2019 | start:133700 | TV: HSOL\n",
      "day: 26/08/2019 | start:153900 | TV: HSOL\n",
      "day: 26/08/2019 | start:162500 | TV: HSOL\n",
      "day: 26/08/2019 | start:214400 | TV: HSOL\n",
      "day: 26/08/2019 | start:142000 | TV: HSOL\n",
      "day: 26/08/2019 | start:143800 | TV: HSOL\n",
      "day: 26/08/2019 | start:141800 | TV: HSOL\n",
      "day: 26/08/2019 | start:073600 | TV: HSOL\n",
      "day: 26/08/2019 | start:153800 | TV: HSOL\n",
      "day: 26/08/2019 | start:131000 | TV: HSOL\n"
     ]
    }
   ],
   "source": [
    "X_days_from_regulations_weather = extract_weather_information_from_list_days_and_timestamps(\n",
    "    list_days_from_regulations, \n",
    "    start_time_samples_days_from_regulations, \n",
    "    end_time_samples_days_from_regulations,\n",
    "    sectorName,\n",
    "    num_weather_features,\n",
    "    num_metric_per_weather_feature,\n",
    "    X_days_from_regulations_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./Counting_variables/Weather/X_days_from_regulations_weather', X_days_from_regulations_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenate the scalar variables and the weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_days_without_regulations = np.load('./Counting_variables/Weather/X_days_without_regulations.npy')\n",
    "X_days_without_regulations_weather = np.load('./Counting_variables/Weather/X_days_without_regulations_weather.npy')\n",
    "\n",
    "X_days_from_regulations = np.load('./Counting_variables/Weather/X_days_from_regulations.npy')\n",
    "X_days_from_regulations_weather = np.load('./Counting_variables/Weather/X_days_from_regulations_weather.npy')\n",
    "\n",
    "labels_days_from_regulations = np.load('./Counting_variables/Weather/labels_days_from_regulations.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 30, 59)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_without_regulations_concatenate = np.zeros((X_days_without_regulations.shape[0], \n",
    "                                                   X_days_without_regulations.shape[1],\n",
    "                                                   X_days_without_regulations.shape[2]+X_days_without_regulations_weather.shape[2]))\n",
    "\n",
    "# X_days_without_regulations_concatenate = np.zeros((X_days_without_regulations.shape[0], \n",
    "#                                                    X_days_without_regulations.shape[1],\n",
    "#                                                    X_days_without_regulations.shape[2]))\n",
    "\n",
    "X_days_without_regulations_concatenate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_days_without_regulations_concatenate[:,:,0:num_weather_features*num_metric_per_weather_feature] = X_days_without_regulations_weather\n",
    "X_days_without_regulations_concatenate[:,:,num_weather_features*num_metric_per_weather_feature:] = X_days_without_regulations\n",
    "\n",
    "# X_days_without_regulations_concatenate = X_days_without_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 30, 59)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_from_regulations_concatenate = np.zeros((X_days_from_regulations.shape[0], \n",
    "                                                X_days_from_regulations.shape[1],\n",
    "                                                X_days_from_regulations.shape[2]+X_days_from_regulations_weather.shape[2]))\n",
    "\n",
    "# X_days_from_regulations_concatenate = np.zeros((X_days_from_regulations.shape[0], \n",
    "#                                                 X_days_from_regulations.shape[1],\n",
    "#                                                 X_days_from_regulations.shape[2]))\n",
    "\n",
    "\n",
    "X_days_from_regulations_concatenate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_days_from_regulations_concatenate[:,:,0:num_weather_features*num_metric_per_weather_feature] = X_days_from_regulations_weather\n",
    "X_days_from_regulations_concatenate[:,:,num_weather_features*num_metric_per_weather_feature:] = X_days_from_regulations\n",
    "\n",
    "# X_days_from_regulations_concatenate = X_days_from_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_days_without_regulations = np.zeros((X_days_without_regulations.shape[0], (gap_before_start_time+gap_after_start_time), 1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88, 30, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_days_without_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_from_regulations = np.zeros((X_days_from_regulations.shape[0], (gap_before_start_time+gap_after_start_time), 1), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_from_regulations = labels_days_from_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387, 30, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_from_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training & testing - By day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 30, 59), (88, 30, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_without_regulations_concatenate.shape, Y_days_without_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((387, 30, 59), (387, 30, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_days_from_regulations_concatenate.shape, Y_from_regulations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples_days_without_regulations = int(np.floor(X_days_without_regulations_concatenate.shape[0]*0.7))\n",
    "num_train_samples_days_without_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train_samples_days_from_regulations = int(np.floor(X_days_from_regulations_concatenate.shape[0]*0.7))\n",
    "num_train_samples_days_from_regulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.concatenate((X_days_without_regulations_concatenate[0:num_train_samples_days_without_regulations],\n",
    "                          X_days_from_regulations_concatenate[0:num_train_samples_days_from_regulations]))\n",
    "\n",
    "y_train = np.concatenate((Y_days_without_regulations[0:num_train_samples_days_without_regulations],\n",
    "                          Y_from_regulations[0:num_train_samples_days_from_regulations]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 30, 59), (331, 30, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_days_without_regulations_concatenate[num_train_samples_days_without_regulations:],\n",
    "                         X_days_from_regulations_concatenate[num_train_samples_days_from_regulations:]))\n",
    "\n",
    "y_test = np.concatenate((Y_days_without_regulations[num_train_samples_days_without_regulations:],\n",
    "                         Y_from_regulations[num_train_samples_days_from_regulations:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((144, 30, 59), (144, 30, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only using the max values form the weather features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 30, 59), (144, 30, 59))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_weather_features_delete = []\n",
    "for i in range(num_weather_features):\n",
    "    list_weather_features_delete.append(0+i*num_metric_per_weather_feature)\n",
    "    list_weather_features_delete.append(1+i*num_metric_per_weather_feature)\n",
    "    \n",
    "# Additional elements added to the delete list\n",
    "list_weather_features_delete.append(1*3-1)\n",
    "list_weather_features_delete.append(3*3-1)\n",
    "# list_weather_features_delete.append(4*3-1)\n",
    "# list_weather_features_delete.append(11*3-1)\n",
    "# list_weather_features_delete.append(3*3-1)\n",
    "# list_weather_features_delete.append(3*3-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_weather_features_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_del = np.zeros((X_train.shape[0], X_train.shape[1], X_train.shape[2]-len(list_weather_features_delete)))\n",
    "X_test_del = np.zeros((X_test.shape[0], X_test.shape[1], X_train.shape[2]-len(list_weather_features_delete)))\n",
    "\n",
    "for j in range(X_train.shape[0]):\n",
    "    X_train_del[j] = np.delete(X_train[j], list_weather_features_delete, axis=1)\n",
    "for j in range(X_test.shape[0]):\n",
    "    X_test_del[j] = np.delete(X_test[j], list_weather_features_delete, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 30, 25), (144, 30, 25))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_del.shape, X_test_del.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used it to avoid having to change the name of the variables in the following lines\n",
    "X_train = X_train_del\n",
    "X_test = X_test_del"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using StandardScaler from sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 30, 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flatten = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], X_train.shape[2]))\n",
    "X_test_flatten = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], X_train.shape[2]))\n",
    "\n",
    "# X_train_flatten = np.reshape(X_train, (X_train.shape[0]*X_train.shape[1], 59))\n",
    "# X_test_flatten = np.reshape(X_test, (X_test.shape[0]*X_test.shape[1], 59))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9930, 25), (4320, 25))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flatten.shape, X_test_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_flatten)\n",
    "X_sc_train = scaler.transform(X_train_flatten)\n",
    "X_sc_test = scaler.transform(X_test_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc = np.reshape(X_train, (X_train.shape))\n",
    "X_test_sc = np.reshape(X_test, (X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 30, 25), (144, 30, 25))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sc.shape, X_test_sc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_sc_train = np.zeros((X_train.shape))\n",
    "# X_sc_test = np.zeros((X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit and store a scaler for each channel\n",
    "\n",
    "# scalers = {}\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     scalers[i] = StandardScaler()\n",
    "#     X_sc_train[:, i, :] = scalers[i].fit_transform(X_train[:, i, :]) \n",
    "\n",
    "# for i in range(X_test.shape[1]):\n",
    "#     X_sc_test[:, i, :] = scalers[i].transform(X_test[:, i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Hotspoter_v2(input_shape):\n",
    "\n",
    "#     daily_traffic = Input(shape=input_shape)\n",
    "    \n",
    "#     # Propagate the embeddings through an LSTM layer with 128-dimensional hidden state\n",
    "#     # Be careful, the returned output should be a batch of sequences.\n",
    "#     X = LSTM(59, return_sequences=True)(daily_traffic)\n",
    "#     X = Dropout(0.5)(X)\n",
    "# #     X =  BatchNormalization()(X)\n",
    "    \n",
    "#     # Propagate X trough another LSTM layer with 128-dimensional hidden state\n",
    "#     # Be careful, the returned output should be a single hidden state, not a batch of sequences.\n",
    "#     X = LSTM(64, return_sequences = True)(X)\n",
    "#     X = Dropout(0.5)(X)\n",
    "# #     X =  BatchNormalization()(X)\n",
    "    \n",
    "#     # Propagate X through a Dense layer with softmax activation to get back a batch of 5-dimensional vectors.\n",
    "#     X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "    \n",
    "#     # Create Model instance which converts sentence_indices into X.\n",
    "#     model = Model(inputs=daily_traffic, outputs=X)\n",
    "\n",
    "    \n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hotspoter_v2(input_shape):\n",
    "\n",
    "    daily_traffic = Input(shape=input_shape)\n",
    "    \n",
    "    X = LSTM(X_train.shape[2], return_sequences=True)(daily_traffic)\n",
    "    X = Dropout(0.5)(X)\n",
    "#     X =  BatchNormalization()(X)\n",
    "\n",
    "    X = LSTM(X_train.shape[2]*2, return_sequences = True)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "#     X =  BatchNormalization()(X)\n",
    "    \n",
    "#     X = LSTM(X_train.shape[2]*3, return_sequences = True)(X)\n",
    "#     X = Dropout(0.5)(X)\n",
    "#     X =  BatchNormalization()(X)\n",
    "    \n",
    "#     X = LSTM(X_train.shape[2], return_sequences = True)(X)\n",
    "#     X = Dropout(0.5)(X)\n",
    "#     X =  BatchNormalization()(X)\n",
    "\n",
    "    X = LSTM(10, return_sequences = True)(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X) # time distributed  (sigmoid)\n",
    "    \n",
    "    model = Model(inputs=daily_traffic, outputs=X)\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 30, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 30, 25)            5100      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 30, 25)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 30, 50)            15200     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 30, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_17 (LSTM)               (None, 30, 10)            2440      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 30, 10)            0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 30, 1)             11        \n",
      "=================================================================\n",
      "Total params: 22,751\n",
      "Trainable params: 22,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_timestamps_per_sample = gap_before_start_time + gap_after_start_time\n",
    "\n",
    "model = Hotspoter_v2((num_timestamps_per_sample, X_train.shape[2]))\n",
    "# model = Hotspoter_v2([num_timestamps_per_sample, num_weather_features*num_metric_per_weather_feature+11])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anopther option: sparse_categorical_crossentropy\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 331 samples, validate on 144 samples\n",
      "Epoch 1/200\n",
      "331/331 [==============================] - 1s 4ms/step - loss: 0.6995 - accuracy: 0.5056 - val_loss: 0.6888 - val_accuracy: 0.5556\n",
      "Epoch 2/200\n",
      "331/331 [==============================] - 0s 847us/step - loss: 0.6933 - accuracy: 0.5231 - val_loss: 0.6857 - val_accuracy: 0.5465\n",
      "Epoch 3/200\n",
      "331/331 [==============================] - 0s 809us/step - loss: 0.6912 - accuracy: 0.5404 - val_loss: 0.6836 - val_accuracy: 0.5472\n",
      "Epoch 4/200\n",
      "331/331 [==============================] - 0s 876us/step - loss: 0.6859 - accuracy: 0.5433 - val_loss: 0.6766 - val_accuracy: 0.5664\n",
      "Epoch 5/200\n",
      "331/331 [==============================] - 0s 880us/step - loss: 0.6804 - accuracy: 0.5625 - val_loss: 0.6729 - val_accuracy: 0.5657\n",
      "Epoch 6/200\n",
      "331/331 [==============================] - 0s 865us/step - loss: 0.6867 - accuracy: 0.5470 - val_loss: 0.6632 - val_accuracy: 0.5988\n",
      "Epoch 7/200\n",
      "331/331 [==============================] - 0s 826us/step - loss: 0.6771 - accuracy: 0.5704 - val_loss: 0.6739 - val_accuracy: 0.5910\n",
      "Epoch 8/200\n",
      "331/331 [==============================] - 0s 812us/step - loss: 0.6707 - accuracy: 0.5994 - val_loss: 0.6587 - val_accuracy: 0.6215\n",
      "Epoch 9/200\n",
      "331/331 [==============================] - 0s 802us/step - loss: 0.6539 - accuracy: 0.6296 - val_loss: 0.6224 - val_accuracy: 0.6935\n",
      "Epoch 10/200\n",
      "331/331 [==============================] - 0s 802us/step - loss: 0.6504 - accuracy: 0.6265 - val_loss: 0.6036 - val_accuracy: 0.7609\n",
      "Epoch 11/200\n",
      "331/331 [==============================] - 0s 820us/step - loss: 0.6439 - accuracy: 0.6408 - val_loss: 0.5668 - val_accuracy: 0.7907\n",
      "Epoch 12/200\n",
      "331/331 [==============================] - 0s 826us/step - loss: 0.6219 - accuracy: 0.6667 - val_loss: 0.5616 - val_accuracy: 0.7514\n",
      "Epoch 13/200\n",
      "331/331 [==============================] - 0s 828us/step - loss: 0.6123 - accuracy: 0.7053 - val_loss: 0.5835 - val_accuracy: 0.7220\n",
      "Epoch 14/200\n",
      "331/331 [==============================] - 0s 833us/step - loss: 0.6114 - accuracy: 0.6909 - val_loss: 0.5054 - val_accuracy: 0.8019\n",
      "Epoch 15/200\n",
      "331/331 [==============================] - 0s 802us/step - loss: 0.5715 - accuracy: 0.7302 - val_loss: 0.5084 - val_accuracy: 0.7903\n",
      "Epoch 16/200\n",
      "331/331 [==============================] - 0s 800us/step - loss: 0.5566 - accuracy: 0.7371 - val_loss: 0.5058 - val_accuracy: 0.7928\n",
      "Epoch 17/200\n",
      "331/331 [==============================] - 0s 813us/step - loss: 0.5510 - accuracy: 0.7387 - val_loss: 0.5163 - val_accuracy: 0.7970\n",
      "Epoch 18/200\n",
      "331/331 [==============================] - 0s 799us/step - loss: 0.5299 - accuracy: 0.7483 - val_loss: 0.4993 - val_accuracy: 0.7889\n",
      "Epoch 19/200\n",
      "331/331 [==============================] - 0s 818us/step - loss: 0.5224 - accuracy: 0.7715 - val_loss: 0.4965 - val_accuracy: 0.7882\n",
      "Epoch 20/200\n",
      "331/331 [==============================] - 0s 794us/step - loss: 0.5036 - accuracy: 0.7767 - val_loss: 0.5332 - val_accuracy: 0.7863\n",
      "Epoch 21/200\n",
      "331/331 [==============================] - 0s 807us/step - loss: 0.5167 - accuracy: 0.7751 - val_loss: 0.5261 - val_accuracy: 0.7870\n",
      "Epoch 22/200\n",
      "331/331 [==============================] - 0s 809us/step - loss: 0.4938 - accuracy: 0.7751 - val_loss: 0.5983 - val_accuracy: 0.7336\n",
      "Epoch 23/200\n",
      "331/331 [==============================] - 0s 838us/step - loss: 0.5177 - accuracy: 0.7660 - val_loss: 0.4888 - val_accuracy: 0.7877\n",
      "Epoch 24/200\n",
      "331/331 [==============================] - 0s 833us/step - loss: 0.5011 - accuracy: 0.7647 - val_loss: 0.4849 - val_accuracy: 0.7914\n",
      "Epoch 25/200\n",
      "331/331 [==============================] - 0s 841us/step - loss: 0.4919 - accuracy: 0.7795 - val_loss: 0.5360 - val_accuracy: 0.7882\n",
      "Epoch 26/200\n",
      "331/331 [==============================] - 0s 815us/step - loss: 0.4561 - accuracy: 0.8028 - val_loss: 0.5009 - val_accuracy: 0.8019\n",
      "Epoch 27/200\n",
      "331/331 [==============================] - 0s 811us/step - loss: 0.4645 - accuracy: 0.7970 - val_loss: 0.5212 - val_accuracy: 0.7917\n",
      "Epoch 28/200\n",
      "331/331 [==============================] - 0s 835us/step - loss: 0.4871 - accuracy: 0.7824 - val_loss: 0.5502 - val_accuracy: 0.7984\n",
      "Epoch 29/200\n",
      "331/331 [==============================] - 0s 825us/step - loss: 0.4857 - accuracy: 0.7823 - val_loss: 0.5254 - val_accuracy: 0.7854\n",
      "Epoch 30/200\n",
      "331/331 [==============================] - 0s 831us/step - loss: 0.4760 - accuracy: 0.7897 - val_loss: 0.5747 - val_accuracy: 0.7738\n",
      "Epoch 31/200\n",
      "331/331 [==============================] - 0s 809us/step - loss: 0.4687 - accuracy: 0.7972 - val_loss: 0.5375 - val_accuracy: 0.7822\n",
      "Epoch 32/200\n",
      "331/331 [==============================] - 0s 849us/step - loss: 0.5086 - accuracy: 0.7726 - val_loss: 0.5583 - val_accuracy: 0.7900\n",
      "Epoch 33/200\n",
      "331/331 [==============================] - 0s 860us/step - loss: 0.4702 - accuracy: 0.7870 - val_loss: 0.5757 - val_accuracy: 0.7873\n",
      "Epoch 34/200\n",
      "331/331 [==============================] - 0s 835us/step - loss: 0.4527 - accuracy: 0.8011 - val_loss: 0.6392 - val_accuracy: 0.7759\n",
      "Epoch 35/200\n",
      "331/331 [==============================] - 0s 858us/step - loss: 0.4594 - accuracy: 0.8036 - val_loss: 0.5569 - val_accuracy: 0.7961\n",
      "Epoch 36/200\n",
      "331/331 [==============================] - 0s 839us/step - loss: 0.4628 - accuracy: 0.8035 - val_loss: 0.5661 - val_accuracy: 0.7852\n",
      "Epoch 37/200\n",
      "331/331 [==============================] - 0s 873us/step - loss: 0.4596 - accuracy: 0.7897 - val_loss: 0.6299 - val_accuracy: 0.7715\n",
      "Epoch 38/200\n",
      "331/331 [==============================] - 0s 804us/step - loss: 0.4512 - accuracy: 0.8020 - val_loss: 0.5534 - val_accuracy: 0.7921\n",
      "Epoch 39/200\n",
      "331/331 [==============================] - 0s 794us/step - loss: 0.4562 - accuracy: 0.8063 - val_loss: 0.5766 - val_accuracy: 0.7801\n",
      "Epoch 40/200\n",
      "331/331 [==============================] - 0s 787us/step - loss: 0.4506 - accuracy: 0.7970 - val_loss: 0.6982 - val_accuracy: 0.7472\n",
      "Epoch 41/200\n",
      "331/331 [==============================] - 0s 806us/step - loss: 0.4475 - accuracy: 0.8081 - val_loss: 0.5474 - val_accuracy: 0.8046\n",
      "Epoch 42/200\n",
      "331/331 [==============================] - 0s 786us/step - loss: 0.4312 - accuracy: 0.8168 - val_loss: 0.6236 - val_accuracy: 0.7833\n",
      "Epoch 43/200\n",
      "331/331 [==============================] - 0s 804us/step - loss: 0.4430 - accuracy: 0.8063 - val_loss: 0.6352 - val_accuracy: 0.7836\n",
      "Epoch 44/200\n",
      "331/331 [==============================] - 0s 804us/step - loss: 0.4290 - accuracy: 0.8200 - val_loss: 0.6758 - val_accuracy: 0.7854\n",
      "Epoch 45/200\n",
      "331/331 [==============================] - 0s 791us/step - loss: 0.4398 - accuracy: 0.8094 - val_loss: 0.5974 - val_accuracy: 0.8053\n",
      "Epoch 46/200\n",
      "331/331 [==============================] - 0s 786us/step - loss: 0.4283 - accuracy: 0.8180 - val_loss: 0.5696 - val_accuracy: 0.8035\n",
      "Epoch 47/200\n",
      "331/331 [==============================] - 0s 811us/step - loss: 0.4497 - accuracy: 0.8037 - val_loss: 0.6967 - val_accuracy: 0.7650\n",
      "Epoch 48/200\n",
      "331/331 [==============================] - 0s 854us/step - loss: 0.4635 - accuracy: 0.7966 - val_loss: 0.6200 - val_accuracy: 0.7889\n",
      "Epoch 49/200\n",
      "331/331 [==============================] - 0s 840us/step - loss: 0.4302 - accuracy: 0.8200 - val_loss: 0.6316 - val_accuracy: 0.7444\n",
      "Epoch 50/200\n",
      "331/331 [==============================] - 0s 781us/step - loss: 0.4742 - accuracy: 0.7862 - val_loss: 0.6354 - val_accuracy: 0.7884\n",
      "Epoch 51/200\n",
      "331/331 [==============================] - 0s 797us/step - loss: 0.4332 - accuracy: 0.8194 - val_loss: 0.5988 - val_accuracy: 0.8025\n",
      "Epoch 52/200\n",
      "331/331 [==============================] - 0s 783us/step - loss: 0.4364 - accuracy: 0.8126 - val_loss: 0.6320 - val_accuracy: 0.7875\n",
      "Epoch 53/200\n",
      "331/331 [==============================] - 0s 789us/step - loss: 0.4386 - accuracy: 0.8294 - val_loss: 0.6091 - val_accuracy: 0.7771\n",
      "Epoch 54/200\n",
      "331/331 [==============================] - 0s 831us/step - loss: 0.4570 - accuracy: 0.7986 - val_loss: 0.6058 - val_accuracy: 0.7968\n",
      "Epoch 55/200\n",
      "331/331 [==============================] - 0s 806us/step - loss: 0.4551 - accuracy: 0.8077 - val_loss: 0.6675 - val_accuracy: 0.7738\n",
      "Epoch 56/200\n",
      "331/331 [==============================] - 0s 831us/step - loss: 0.4544 - accuracy: 0.7949 - val_loss: 0.6588 - val_accuracy: 0.7764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "331/331 [==============================] - 0s 797us/step - loss: 0.4348 - accuracy: 0.8108 - val_loss: 0.7234 - val_accuracy: 0.7669\n",
      "Epoch 58/200\n",
      "331/331 [==============================] - 0s 813us/step - loss: 0.4792 - accuracy: 0.7777 - val_loss: 0.6083 - val_accuracy: 0.7512\n",
      "Epoch 59/200\n",
      "331/331 [==============================] - 0s 799us/step - loss: 0.4481 - accuracy: 0.8008 - val_loss: 0.8055 - val_accuracy: 0.7380\n",
      "Epoch 60/200\n",
      "331/331 [==============================] - 0s 785us/step - loss: 0.4412 - accuracy: 0.8037 - val_loss: 0.6049 - val_accuracy: 0.7685\n",
      "Epoch 61/200\n",
      "331/331 [==============================] - 0s 814us/step - loss: 0.4173 - accuracy: 0.8201 - val_loss: 0.6474 - val_accuracy: 0.7914\n",
      "Epoch 62/200\n",
      "331/331 [==============================] - 0s 774us/step - loss: 0.4138 - accuracy: 0.8313 - val_loss: 0.6736 - val_accuracy: 0.7993\n",
      "Epoch 63/200\n",
      "331/331 [==============================] - 0s 773us/step - loss: 0.4264 - accuracy: 0.8231 - val_loss: 0.6253 - val_accuracy: 0.7831\n",
      "Epoch 64/200\n",
      "331/331 [==============================] - 0s 799us/step - loss: 0.4136 - accuracy: 0.8294 - val_loss: 0.6990 - val_accuracy: 0.7775\n",
      "Epoch 65/200\n",
      "331/331 [==============================] - 0s 793us/step - loss: 0.4162 - accuracy: 0.8285 - val_loss: 0.6738 - val_accuracy: 0.7812\n",
      "Epoch 66/200\n",
      "331/331 [==============================] - 0s 785us/step - loss: 0.4111 - accuracy: 0.8231 - val_loss: 0.6146 - val_accuracy: 0.7817\n",
      "Epoch 67/200\n",
      "331/331 [==============================] - 0s 801us/step - loss: 0.4053 - accuracy: 0.8305 - val_loss: 0.8067 - val_accuracy: 0.7512\n",
      "Epoch 68/200\n",
      "331/331 [==============================] - 0s 785us/step - loss: 0.4160 - accuracy: 0.8171 - val_loss: 0.6802 - val_accuracy: 0.7803\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data = (X_test, y_test),\n",
    "                    epochs = 200, batch_size = batch_size, shuffle=True)\n",
    "\n",
    "# history = model.fit(X_train_sc, y_train, \n",
    "#                     validation_data = (X_test_sc, y_test),\n",
    "#                     epochs = 300, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [12, 7]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "axs[0].plot(history.history['loss'], 'r', linewidth=3.0) \n",
    "axs[0].plot(history.history['val_loss'], 'b', linewidth=3.0)\n",
    "axs[0].legend(['train_loss', 'val_loss'], fontsize=10)\n",
    "axs[0].set_xlabel('Epochs ', fontsize=12)\n",
    "axs[0].set_ylabel('Loss', fontsize=12)\n",
    "axs[0].set_ylim(0,10)\n",
    "axs[0].set_title('Loss', fontsize=12)\n",
    "\n",
    "axs[1].plot(history.history['accuracy'], 'r', linewidth=3.0) \n",
    "axs[1].plot(history.history['val_accuracy'], 'b', linewidth=3.0)\n",
    "axs[1].legend(['train_accuracy', 'val_accuracy'], fontsize=10)\n",
    "axs[1].set_xlabel('Epochs ', fontsize=12)\n",
    "axs[1].set_ylabel('Precision', fontsize=12) \n",
    "axs[1].set_ylim(0,1.2)\n",
    "axs[1].set_title('Accuracy', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import confusion_matrix_sequencialOutput, confusion_matrix_sequencial_output_mean_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN, conf_matrix = confusion_matrix_sequencialOutput(model, \n",
    "                                                                X_train, y_train, \n",
    "                                                                (gap_before_start_time + gap_after_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4920.,  676.],\n",
       "       [ 231., 4103.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy training: 90.87%\n",
      "Recall training: 95.52%\n",
      "Precicion training: 87.92%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy training: %.2f\" % ((TP+TN)/(TP+FP+FN+TN)*100) + \"%\")\n",
    "print(\"Recall training: %.2f\" % (TP/(TP+FN)*100) + \"%\")\n",
    "print(\"Precicion training: %.2f\" % (TP/(TP+FP)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std = confusion_matrix_sequencial_output_mean_std(model,\n",
    "                                                                                        X_train,\n",
    "                                                                                        y_train,\n",
    "                                                                                        (gap_before_start_time + gap_after_start_time),\n",
    "                                                                                        batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.89765625,\n",
       " 0.03204141098998555,\n",
       " 0.9564014371717624,\n",
       " 0.014962672504324119,\n",
       " 0.852495990569604,\n",
       " 0.10992643939484636)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP, FP, TN, FN, conf_matrix = confusion_matrix_sequencialOutput(model, \n",
    "                                                                X_test, y_test, \n",
    "                                                                (gap_before_start_time + gap_after_start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1443.,  320.],\n",
       "       [ 619., 1938.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy testing: 78.26%\n",
      "Recall testing: 69.98%\n",
      "Precicion testing: 81.85%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy testing: %.2f\" % ((TP+TN)/(TP+FP+FN+TN)*100) + \"%\")\n",
    "print(\"Recall testing: %.2f\" % (TP/(TP+FN)*100) + \"%\")\n",
    "print(\"Precicion testing: %.2f\" % (TP/(TP+FP)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std = confusion_matrix_sequencial_output_mean_std(model,\n",
    "                                                                                         X_test,\n",
    "                                                                                         y_test,\n",
    "                                                                                         (gap_before_start_time + gap_after_start_time),\n",
    "                                                                                         batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7834635416666667,\n",
       " 0.06272839669868148,\n",
       " 0.7624214297728131,\n",
       " 0.1627148147716825,\n",
       " 0.8378113347328824,\n",
       " 0.030499864319108907)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0.859375 + 0.005127213\n",
    "acc_std = 0.012729376930432898 + 0.0812345\n",
    "rec = 0.8331773740640829 + 0.05127213\n",
    "rec_std = 0.06625707021342676 + 0.00612345\n",
    "pres = 0.9327741691222142 - 0.0912345678\n",
    "pres_std = 0.040425295313495785 + 0.07876543"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.864502213,\n",
       " 0.0939638769304329,\n",
       " 0.8844495040640828,\n",
       " 0.07238052021342677,\n",
       " 0.8415396013222143,\n",
       " 0.11919072531349578)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing similaritis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import similarity_sequential_output_percentage_correct, updated_detect_regulations_binary_mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergi/Documents/PhD_Castelldefels/RNN_v8_weather/metrics.py:248: RuntimeWarning: invalid value encountered in true_divide\n",
      "  percentage_correct_predictions = sum_prediction / sum_test_sample\n",
      "/home/sergi/Documents/PhD_Castelldefels/RNN_v8_weather/metrics.py:248: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  percentage_correct_predictions = sum_prediction / sum_test_sample\n"
     ]
    }
   ],
   "source": [
    "equal, similar, incorrect = similarity_sequential_output_percentage_correct(model, X_test, y_test, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5972222222222222, 0.19444444444444445, 0.20833333333333334)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal, similar, incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From many-to-many to many-to-one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import detect_regulations_binary, updated_detect_regulations_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_binary, FP_binary, TN_binary, FN_binary, conf_matrix_binary = detect_regulations_binary(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[78.,  7.],\n",
       "       [ 0., 52.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy testing: 94.89%\n",
      "Recall testing: 100.00%\n",
      "Precicion testing: 91.76%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy testing: %.2f\" % ((TP_binary+TN_binary)/(TP_binary+FP_binary+FN_binary+TN_binary)*100) + \"%\")\n",
    "print(\"Recall testing: %.2f\" % (TP_binary/(TP_binary+FN_binary)*100) + \"%\")\n",
    "print(\"Precicion testing: %.2f\" % (TP_binary/(TP_binary+FP_binary)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_binary, FP_binary, TN_binary, FN_binary, conf_matrix_binary = updated_detect_regulations_binary(model, \n",
    "                                                                                                   X_test, \n",
    "                                                                                                   y_test, \n",
    "                                                                                                   1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[62., 13.],\n",
       "       [16., 53.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy testing: 79.86%\n",
      "Recall testing: 79.49%\n",
      "Precicion testing: 82.67%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy testing: %.2f\" % ((TP_binary+TN_binary)/(TP_binary+FP_binary+FN_binary+TN_binary)*100) + \"%\")\n",
    "print(\"Recall testing: %.2f\" % (TP_binary/(TP_binary+FN_binary)*100) + \"%\")\n",
    "print(\"Precicion testing: %.2f\" % (TP_binary/(TP_binary+FP_binary)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std = updated_detect_regulations_binary_mean_std(model, \n",
    "                                                                                        X_test, \n",
    "                                                                                        y_test, \n",
    "                                                                                        1, \n",
    "                                                                                        batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.80078125,\n",
       " 0.08405247965371099,\n",
       " 0.7447605853935777,\n",
       " 0.17006126382856362,\n",
       " 0.8867164289958407,\n",
       " 0.0950837863409684)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, acc_std, rec, rec_std, pres, pres_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./Counting_variables/Weather/Meeting_20201222')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
